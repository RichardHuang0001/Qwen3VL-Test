"""
è¯„ä¼°æ¨¡å‹æ£€æµ‹å‡†ç¡®ç‡
è®¡ç®— Precision, Recall, F1-Score, mAP ç­‰æŒ‡æ ‡
"""

import json
import yaml
import xml.etree.ElementTree as ET
from pathlib import Path
from collections import defaultdict
from tqdm import tqdm
import re

# ============================
# ğŸ“Œ é…ç½®åŒºåŸŸï¼šé€‰æ‹©è¦è¯„ä¼°çš„ç»“æœæ–‡ä»¶
# ============================

# é€‰é¡¹1: è‡ªåŠ¨ä½¿ç”¨æœ€æ–°çš„ç»“æœæ–‡ä»¶ï¼ˆé»˜è®¤ï¼‰
USE_LATEST_RESULT = True

# é€‰é¡¹2: æ‰‹åŠ¨æŒ‡å®šç»“æœæ–‡ä»¶åï¼ˆå½“ USE_LATEST_RESULT = False æ—¶ç”Ÿæ•ˆï¼‰
# ç¤ºä¾‹: "api_raw_results_20260110_155552.jsonl"
SPECIFIC_RESULT_FILE = "api_raw_results_20260110_155552.jsonl"

# ============================

# --- ç±»åˆ«æ˜ å°„ ---
# XMLæ ‡æ³¨ä¸­çš„ç±»åˆ« -> æ¨¡å‹è¾“å‡ºçš„ç±»åˆ«
# æ”¯æŒV2ç‰ˆæœ¬ï¼ˆè€ï¼‰å’ŒV3ç‰ˆæœ¬ï¼ˆæ–°ï¼‰çš„æ¨¡å‹è¾“å‡º
CLASS_MAPPING = {
    'D00': 'longitudinal_crack',  # çºµå‘è£‚ç¼
    'D10': 'transverse_crack',     # æ¨ªå‘è£‚ç¼
    'D20': 'alligator_crack',      # ç½‘çŠ¶è£‚ç¼
    'D40': 'pothole',              # å‘æ§½
    'Repair': 'repair'             # ä¿®è¡¥åŒºåŸŸ
}

# åå‘æ˜ å°„
REVERSE_CLASS_MAPPING = {v: k for k, v in CLASS_MAPPING.items()}

# æ¨¡å‹æ ‡ç­¾çš„é¢„å¤„ç†æ˜ å°„ï¼ˆå¤„ç†V2ç‰ˆæœ¬çš„"crack"æ ‡ç­¾ï¼‰
# å°†æ—§ç‰ˆæœ¬çš„æ¨¡ç³Šæ ‡ç­¾æ˜ å°„åˆ°æ–°ç‰ˆæœ¬çš„å…·ä½“æ ‡ç­¾
LABEL_NORMALIZATION = {
    'crack': None,  # æ—§ç‰ˆé€šç”¨æ ‡ç­¾ï¼Œå°†è¢«è·³è¿‡ï¼ˆå› ä¸ºæ— æ³•ç¡®å®šå…·ä½“ç±»åˆ«ï¼‰
    'longitudinal_crack': 'longitudinal_crack',
    'transverse_crack': 'transverse_crack',
    'alligator_crack': 'alligator_crack',
    'pothole': 'pothole',
    'repair': 'repair'
}

# --- è¾…åŠ©å‡½æ•° ---

def load_config(config_path="config.yaml") -> dict:
    """åŠ è½½å…¨å±€ YAML é…ç½®æ–‡ä»¶"""
    root_dir = Path(__file__).parent.parent.parent
    config_file_path = root_dir / config_path
    
    try:
        with open(config_file_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šé…ç½®æ–‡ä»¶ '{config_file_path}' æœªæ‰¾åˆ°ã€‚")
        exit(1)
    except Exception as e:
        print(f"åŠ è½½ config.yaml æ—¶å‡ºé”™: {e}")
        exit(1)

def parse_xml_annotation(xml_path: Path) -> dict:
    """
    è§£æXMLæ ‡æ³¨æ–‡ä»¶ï¼Œæå–Ground Truth
    è¿”å›: {'width': int, 'height': int, 'objects': [{'class': str, 'bbox': [xmin, ymin, xmax, ymax]}, ...]}
    """
    try:
        # è·³è¿‡macOSéšè—æ–‡ä»¶ï¼ˆä»¥._å¼€å¤´çš„æ–‡ä»¶ï¼‰
        if xml_path.name.startswith('._'):
            return None
        
        tree = ET.parse(xml_path)
        root = tree.getroot()
        
        # è·å–å›¾ç‰‡å°ºå¯¸
        size = root.find('size')
        width = int(float(size.find('width').text))  # æ”¯æŒå°æ•°åæ ‡
        height = int(float(size.find('height').text))
        
        # æå–æ‰€æœ‰æ ‡æ³¨å¯¹è±¡
        objects = []
        for obj in root.findall('object'):
            name = obj.find('name').text  # D00, D10, D20, D40
            bndbox = obj.find('bndbox')
            
            # è½¬æ¢ä¸ºæ•´æ•°ï¼Œæ”¯æŒå°æ•°åæ ‡
            bbox = [
                int(float(bndbox.find('xmin').text)),
                int(float(bndbox.find('ymin').text)),
                int(float(bndbox.find('xmax').text)),
                int(float(bndbox.find('ymax').text))
            ]
            
            objects.append({
                'class': name,
                'bbox': bbox
            })
        
        return {
            'width': width,
            'height': height,
            'objects': objects
        }
    except Exception as e:
        # ä¼˜åŒ–é”™è¯¯æç¤ºï¼Œè·³è¿‡macOSéšè—æ–‡ä»¶çš„æ— ç”¨è­¦å‘Š
        if not xml_path.name.startswith('._'):
            print(f"è­¦å‘Šï¼šè§£æ {xml_path.name} å¤±è´¥: {e}")
        return None

def parse_model_content(content_str: str) -> dict:
    """
    ä»æ¨¡å‹è¿”å›çš„ content å­—ç¬¦ä¸²ä¸­æå– JSON
    å¤„ç† ```json ... ``` æ ‡è®°
    """
    match = re.search(r'```json\s*(\{.*?\})\s*```', content_str, re.DOTALL)
    
    if match:
        json_str = match.group(1)
    else:
        json_str = content_str.strip()
        
    try:
        json_str = json_str.replace(r'\n', '\n')
        return json.loads(json_str)
    except json.JSONDecodeError:
        return None

def calculate_iou(box1, box2):
    """
    è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„IoU (Intersection over Union)
    box1, box2: [xmin, ymin, xmax, ymax] (ç»å¯¹åƒç´ åæ ‡)
    """
    x1_min, y1_min, x1_max, y1_max = box1
    x2_min, y2_min, x2_max, y2_max = box2
    
    # è®¡ç®—äº¤é›†
    inter_xmin = max(x1_min, x2_min)
    inter_ymin = max(y1_min, y2_min)
    inter_xmax = min(x1_max, x2_max)
    inter_ymax = min(y1_max, y2_max)
    
    if inter_xmax < inter_xmin or inter_ymax < inter_ymin:
        return 0.0
    
    inter_area = (inter_xmax - inter_xmin) * (inter_ymax - inter_ymin)
    
    # è®¡ç®—å¹¶é›†
    box1_area = (x1_max - x1_min) * (y1_max - y1_min)
    box2_area = (x2_max - x2_min) * (y2_max - y2_min)
    union_area = box1_area + box2_area - inter_area
    
    return inter_area / union_area if union_area > 0 else 0.0

def convert_relative_to_absolute(box_2d, img_width, img_height):
    """
    å°†ç›¸å¯¹åæ ‡è½¬æ¢ä¸ºç»å¯¹åƒç´ åæ ‡
    box_2d: [ymin, xmin, ymax, xmax] (ç›¸å¯¹åæ ‡ 0-1)
    è¿”å›: [xmin, ymin, xmax, ymax] (ç»å¯¹åƒç´ åæ ‡)
    """
    ymin_rel, xmin_rel, ymax_rel, xmax_rel = box_2d
    
    xmin = int(xmin_rel * img_width)
    ymin = int(ymin_rel * img_height)
    xmax = int(xmax_rel * img_width)
    ymax = int(ymax_rel * img_height)
    
    return [xmin, ymin, xmax, ymax]

# --- ä¸»è¯„ä¼°å‡½æ•° ---

def evaluate_detections(ground_truths, predictions, iou_threshold=0.5):
    """
    è¯„ä¼°æ£€æµ‹ç»“æœ
    
    å‚æ•°:
        ground_truths: {image_id: {'width': w, 'height': h, 'objects': [...]}}
        predictions: {image_id: {'width': w, 'height': h, 'detections': [...]}}
        iou_threshold: IoUé˜ˆå€¼ï¼Œé»˜è®¤0.5
    
    è¿”å›:
        metrics: å„ç±»åˆ«çš„ precision, recall, f1, ap ç­‰æŒ‡æ ‡
    """
    # æŒ‰ç±»åˆ«ç»Ÿè®¡
    class_stats = defaultdict(lambda: {
        'tp': 0,  # True Positives
        'fp': 0,  # False Positives
        'fn': 0,  # False Negatives (ground truthæœªè¢«æ£€æµ‹åˆ°)
        'matched_pairs': []  # (é¢„æµ‹ç½®ä¿¡åº¦, IoU, æ˜¯å¦æ­£ç¡®åŒ¹é…)
    })
    
    # éå†æ¯å¼ å›¾ç‰‡
    for image_id in tqdm(ground_truths.keys(), desc="è¯„ä¼°æ£€æµ‹ç»“æœ"):
        gt_data = ground_truths.get(image_id)
        pred_data = predictions.get(image_id)
        
        if not gt_data:
            continue
        
        img_width = gt_data['width']
        img_height = gt_data['height']
        gt_objects = gt_data['objects']
        
        # å¦‚æœæ²¡æœ‰é¢„æµ‹ç»“æœ
        if not pred_data or not pred_data.get('detections'):
            # æ‰€æœ‰ground truthéƒ½æ˜¯false negatives
            for gt_obj in gt_objects:
                gt_class = CLASS_MAPPING.get(gt_obj['class'])
                if gt_class:
                    class_stats[gt_class]['fn'] += 1
            continue
        
        pred_detections = pred_data['detections']
        
        # æŒ‰ç±»åˆ«åˆ†ç»„
        gt_by_class = defaultdict(list)
        for gt_obj in gt_objects:
            gt_class_mapped = CLASS_MAPPING.get(gt_obj['class'])
            if gt_class_mapped:
                gt_by_class[gt_class_mapped].append(gt_obj['bbox'])
        
        pred_by_class = defaultdict(list)
        for pred in pred_detections:
            pred_class = pred.get('label')
            pred_box_rel = pred.get('box_2d')
            
            # æ ‡ç­¾è§„èŒƒåŒ–å¤„ç†ï¼ˆå¤„ç†V2ç‰ˆæœ¬çš„"crack"æ ‡ç­¾ï¼‰
            if pred_class in LABEL_NORMALIZATION:
                normalized_label = LABEL_NORMALIZATION[pred_class]
                # è·³è¿‡æ— æ³•ç¡®å®šå…·ä½“ç±»åˆ«çš„æ ‡ç­¾
                if normalized_label is None:
                    continue
                pred_class = normalized_label
            
            if pred_class and pred_box_rel and len(pred_box_rel) == 4:
                # è½¬æ¢ä¸ºç»å¯¹åæ ‡ [xmin, ymin, xmax, ymax]
                pred_box_abs = convert_relative_to_absolute(
                    pred_box_rel, img_width, img_height
                )
                pred_by_class[pred_class].append(pred_box_abs)
        
        # å¯¹æ¯ä¸ªç±»åˆ«è¿›è¡ŒåŒ¹é…
        for class_name in set(list(gt_by_class.keys()) + list(pred_by_class.keys())):
            gt_boxes = gt_by_class[class_name]
            pred_boxes = pred_by_class[class_name]
            
            matched_gt = set()  # å·²åŒ¹é…çš„ground truthç´¢å¼•
            
            # å¯¹æ¯ä¸ªé¢„æµ‹æ¡†
            for pred_box in pred_boxes:
                best_iou = 0
                best_gt_idx = -1
                
                # æ‰¾åˆ°æœ€ä½³åŒ¹é…çš„ground truth
                for gt_idx, gt_box in enumerate(gt_boxes):
                    if gt_idx in matched_gt:
                        continue
                    
                    iou = calculate_iou(pred_box, gt_box)
                    if iou > best_iou:
                        best_iou = iou
                        best_gt_idx = gt_idx
                
                # åˆ¤æ–­æ˜¯å¦åŒ¹é…æˆåŠŸ
                if best_iou >= iou_threshold and best_gt_idx >= 0:
                    class_stats[class_name]['tp'] += 1
                    matched_gt.add(best_gt_idx)
                else:
                    class_stats[class_name]['fp'] += 1
            
            # æœªåŒ¹é…çš„ground truthä¸ºfalse negatives
            unmatched_gt_count = len(gt_boxes) - len(matched_gt)
            class_stats[class_name]['fn'] += unmatched_gt_count
    
    # è®¡ç®—å„ç±»åˆ«æŒ‡æ ‡
    results = {}
    for class_name, stats in class_stats.items():
        tp = stats['tp']
        fp = stats['fp']
        fn = stats['fn']
        
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0
        
        results[class_name] = {
            'tp': tp,
            'fp': fp,
            'fn': fn,
            'precision': precision,
            'recall': recall,
            'f1': f1
        }
    
    # è®¡ç®—æ€»ä½“æŒ‡æ ‡ (macro average)
    if results:
        avg_precision = sum(r['precision'] for r in results.values()) / len(results)
        avg_recall = sum(r['recall'] for r in results.values()) / len(results)
        avg_f1 = sum(r['f1'] for r in results.values()) / len(results)
        
        results['macro_average'] = {
            'precision': avg_precision,
            'recall': avg_recall,
            'f1': avg_f1
        }
    
    return results

# --- ä¸»å‡½æ•° ---

def main():
    print("--- å¯åŠ¨æ£€æµ‹ç»“æœè¯„ä¼°è„šæœ¬ ---\n")
    
    # 1. åŠ è½½é…ç½®
    config = load_config()
    root_dir = Path(__file__).parent.parent.parent
    
    raw_data_dir = root_dir / config['data']['raw_dir']
    results_dir = root_dir / config['results']['output_dir']
    
    # 2. é€‰æ‹©è¦è¯„ä¼°çš„ç»“æœæ–‡ä»¶
    if USE_LATEST_RESULT:
        # è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„ç»“æœæ–‡ä»¶
        result_files = list(results_dir.glob("api_raw_results*.jsonl"))
        if not result_files:
            print(f"é”™è¯¯ï¼šåœ¨ {results_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½•ç»“æœæ–‡ä»¶ã€‚")
            return
        
        latest_result_file = max(result_files, key=lambda p: p.stat().st_mtime)
        print(f"[æ¨¡å¼] è‡ªåŠ¨é€‰æ‹©æœ€æ–°ç»“æœæ–‡ä»¶")
        print(f"[ä¿¡æ¯] ä½¿ç”¨ç»“æœæ–‡ä»¶: {latest_result_file.name}\n")
    else:
        # ä½¿ç”¨æ‰‹åŠ¨æŒ‡å®šçš„ç»“æœæ–‡ä»¶
        latest_result_file = results_dir / SPECIFIC_RESULT_FILE
        if not latest_result_file.exists():
            print(f"é”™è¯¯ï¼šæŒ‡å®šçš„ç»“æœæ–‡ä»¶ '{SPECIFIC_RESULT_FILE}' ä¸å­˜åœ¨ã€‚")
            print(f"è¯·æ£€æŸ¥è·¯å¾„ï¼š{latest_result_file}")
            return
        
        print(f"[æ¨¡å¼] ä½¿ç”¨æŒ‡å®šçš„ç»“æœæ–‡ä»¶")
        print(f"[ä¿¡æ¯] è¯„ä¼°æ–‡ä»¶: {latest_result_file.name}\n")
    
    # 3. åŠ è½½Ground Truth (XMLæ ‡æ³¨)
    print("[æ­¥éª¤ 1/4] åŠ è½½Ground Truthæ ‡æ³¨...")
    xml_files = list(raw_data_dir.rglob('*.xml'))
    # è¿‡æ»¤æ‰macOSéšè—æ–‡ä»¶
    xml_files = [f for f in xml_files if not f.name.startswith('._')]
    
    ground_truths = {}
    for xml_path in tqdm(xml_files, desc="è§£æXML"):
        gt_data = parse_xml_annotation(xml_path)
        if gt_data and gt_data['objects']:  # åªä¿ç•™æœ‰æ ‡æ³¨çš„å›¾ç‰‡
            # ä½¿ç”¨ç›¸å¯¹è·¯å¾„ä½œä¸ºimage_id (å»æ‰æ‰©å±•å)
            image_id = str(xml_path.relative_to(raw_data_dir).with_suffix('').with_suffix(''))
            # è§„èŒƒåŒ–è·¯å¾„åˆ†éš”ç¬¦
            image_id = image_id.replace('\\', '/')
            ground_truths[image_id] = gt_data
    
    print(f"åŠ è½½äº† {len(ground_truths)} å¼ æœ‰æ ‡æ³¨çš„å›¾ç‰‡\n")
    
    # 4. åŠ è½½Predictions (APIç»“æœ)
    print("[æ­¥éª¤ 2/4] åŠ è½½æ¨¡å‹é¢„æµ‹ç»“æœ...")
    predictions = {}
    
    with open(latest_result_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()
        
        for line in tqdm(lines, desc="è§£æé¢„æµ‹"):
            try:
                data = json.loads(line)
                
                if data.get("error") or "response" not in data:
                    continue
                
                image_id = data["custom_id"]
                content_str = data["response"]["body"]["choices"][0]["message"]["content"]
                
                model_output = parse_model_content(content_str)
                if not model_output:
                    continue
                
                # è·å–å›¾ç‰‡å°ºå¯¸ (ä»ground truthä¸­è·å–)
                if image_id in ground_truths:
                    predictions[image_id] = {
                        'width': ground_truths[image_id]['width'],
                        'height': ground_truths[image_id]['height'],
                        'detections': model_output.get('detections', [])
                    }
            
            except Exception as e:
                continue
    
    print(f"åŠ è½½äº† {len(predictions)} å¼ å›¾ç‰‡çš„é¢„æµ‹ç»“æœ\n")
    
    # 5. è¯„ä¼°
    print("[æ­¥éª¤ 3/4] è®¡ç®—è¯„ä¼°æŒ‡æ ‡...")
    iou_threshold = 0.5
    metrics = evaluate_detections(ground_truths, predictions, iou_threshold)
    
    # 6. æ‰“å°ç»“æœ
    print(f"\n[æ­¥éª¤ 4/4] è¯„ä¼°å®Œæˆï¼(IoUé˜ˆå€¼ = {iou_threshold})\n")
    print("=" * 80)
    print(f"{'ç±»åˆ«':<25} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'TP/FP/FN'}")
    print("=" * 80)
    
    # ç±»åˆ«åç§°æ˜ å°„ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    class_display_names = {
        'longitudinal_crack': 'D00-çºµå‘è£‚ç¼',
        'transverse_crack': 'D10-æ¨ªå‘è£‚ç¼',
        'alligator_crack': 'D20-ç½‘çŠ¶è£‚ç¼',
        'pothole': 'D40-å‘æ§½'
    }
    
    for class_name in ['longitudinal_crack', 'transverse_crack', 'alligator_crack', 'pothole']:
        if class_name in metrics:
            m = metrics[class_name]
            display_name = class_display_names.get(class_name, class_name)
            print(f"{display_name:<25} {m['precision']:<12.3f} {m['recall']:<12.3f} "
                  f"{m['f1']:<12.3f} {m['tp']}/{m['fp']}/{m['fn']}")
        else:
            display_name = class_display_names.get(class_name, class_name)
            print(f"{display_name:<25} {'N/A':<12} {'N/A':<12} {'N/A':<12} 0/0/0")
    
    print("-" * 80)
    
    if 'macro_average' in metrics:
        m = metrics['macro_average']
        print(f"{'å®å¹³å‡ (Macro Avg)':<25} {m['precision']:<12.3f} {m['recall']:<12.3f} "
              f"{m['f1']:<12.3f}")
    
    print("=" * 80)
    
    # 7. ä¿å­˜è¯¦ç»†ç»“æœåˆ°JSON
    output_file = results_dir / "evaluation_metrics.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(metrics, f, indent=2, ensure_ascii=False)
    
    print(f"\nè¯¦ç»†è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print("\n--- è¯„ä¼°å®Œæˆ ---")

if __name__ == "__main__":
    main()
